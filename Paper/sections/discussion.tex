The goal of this system is to be able to run in real-time and help the user to understand how good he or she performed an action. It also should provide a score to the accuracy of the entire session to help the user understand how much he or she has improved. In addition, we would like to provide a summary about the accuracy of performing each action and the parts of action that have the highest error rate.

In order to notify the user about the inaccurate parts in his or her performance we proposed that we can vibrate the cell phone when there is an error in some part of the action. Another possible approach is to show the places of error on the movement path. However we cannot measure the position using the phone sensors. A possible approach for constructing the movement trajectory from the mobile sensors is to use an Extended Kalman filter. \cite{sabatini2006quaternion} proposed a method with Extended Kalman filters that can recognize the position using the accelerometer, gyroscope, and magnetometer. The proposed filter aims to not only determine the position via an orientation quaternion, but also the accelerometer and magnetometer bias. Understanding the bias from the accelerometer as well as the orientation quaternion can help us better understand what the true movement of the user is like.

Another issue of the current system is with the DTW algorithm. DTW needs $T^2$ computations, where $T$ is the length of a query gesture. This might cause problems when the length of a gesture is long. \cite{salvador2007toward} proposed a modified version of this algorithm that is able to process in $T$ computations and claimed that it is more accurate than the other methods for DTW. The FastDTW computes a subsample of a sequence with length $\sqrt{T}$ and by limiting the search space computes the distance in a time less than $T$. Then it projects the estimated path from the subsampled sequence on the entire sequence and tries to estimate the correct points within a radius of frames around the estimated path.


